{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for iterating\n",
    "from itertools import product\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# to tune models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# to cross-validate models\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# to save the model\n",
    "import joblib\n",
    "\n",
    "# to evaluate models\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "project_name = \"RF+Clust\"\n",
    "project_folder = f\"C:/Users/anani/Downloads/{project_name}\"\n",
    "sys.path.append(project_folder)\n",
    "\n",
    "from variables import suite_name, features, target, transformation, budgets, algorithms\n",
    "from variables import n_folds, crossval_column\n",
    "from variables import model_name\n",
    "from utils import read_fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "if features != \"all\":\n",
    "    data_folder = f\"{project_folder}/Data/{suite_name}/preprocessed/transformation={transformation}_features={features}/{model_name}\"\n",
    "else: \n",
    "    data_folder = f\"{project_folder}/Data/{suite_name}/preprocessed/transformation={transformation}_features={features}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "results_folder = f\"{project_folder}/Results/{suite_name}/transformation={transformation}_features={features}/{model_name}\"\n",
    "os.makedirs(results_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_hyperparameters(model_name: str):\n",
    "    \"\"\"\n",
    "    Function to create a ML algorithm parameter grid.\n",
    "    \"\"\"\n",
    "    if model_name == 'random_forest':\n",
    "            return dict(n_estimators=[10, 20, 50, 70]\n",
    "                        , max_depth=[3, 5, 7, 10]\n",
    "                        , max_features=[1.0, 'sqrt', 'log2']\n",
    "                        , min_samples_split=[2, 5, 7, 10]\n",
    "                        , random_state=[1]\n",
    "                        )\n",
    "        \n",
    "def get_model(model_name: str, model_kwargs: dict):\n",
    "    \"\"\"\n",
    "    Function to initialize a ML model instance.\n",
    "    \"\"\"\n",
    "    if model_name == 'random_forest':\n",
    "        return RandomForestRegressor(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train: pd.DataFrame, y_train: pd.DataFrame, model_name: str, cv: object, cv_groups: list, scoring: str):\n",
    "    \"\"\"\n",
    "    Function to tuned model with grid search.\n",
    "    \"\"\"\n",
    "    # get model \n",
    "    model_init = get_model(model_name=model_name, model_kwargs={})\n",
    "    \n",
    "    # get param grid\n",
    "    model_params_grid = get_model_hyperparameters(model_name)\n",
    "    print(f\"parameter grid: {model_params_grid}\")\n",
    "\n",
    "    # perform model tunning\n",
    "    grid = GridSearchCV(estimator=model_init, param_grid=model_params_grid, cv=cv, scoring=scoring\n",
    "                         , return_train_score=True, verbose=3).fit(X=X_train, y=y_train, groups=cv_groups)\n",
    " \n",
    "    return grid.best_estimator_, pd.DataFrame(grid.best_params_, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_summary(true_train: list, predicted_train: list, true_test: list, predicted_test: list): \n",
    "    \"\"\"\n",
    "    Function to calculate model performance with respect to different metrics.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\"mae_train\": mean_absolute_error(true_train, predicted_train)\n",
    "            , \"mae_test\": mean_absolute_error(true_test, predicted_test)\n",
    "            , \"mdae_train\": median_absolute_error(true_train, predicted_train)\n",
    "            , \"mdae_test\": median_absolute_error(true_test, predicted_test)\n",
    "            , \"r2_train\": r2_score(true_train, predicted_train)\n",
    "            , \"r2_test\": r2_score(true_test, predicted_test)}\n",
    "            , index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for algorithm_name, budget in product(algorithms, budgets):\n",
    "    print(f\"Algorithm name: {algorithm_name}, budget: {budget}\")\n",
    "\n",
    "    # define directories\n",
    "    data_folder_temp = f\"{data_folder}/algorithm_name={algorithm_name}_budget={budget}\"\n",
    "    results_folder_temp = f\"{results_folder}/algorithm_name={algorithm_name}_budget={budget}\"\n",
    "    \n",
    "    # create directories\n",
    "    os.makedirs(f\"{results_folder_temp}/models\", exist_ok=True)\n",
    "    os.makedirs(f\"{results_folder_temp}/predictions\", exist_ok=True)\n",
    "\n",
    "    # create results placeholders\n",
    "    performance = pd.DataFrame()\n",
    "    parameters = pd.DataFrame()\n",
    "    predictions = pd.DataFrame()\n",
    "    \n",
    "    for fold_number in np.arange(1, n_folds+1):\n",
    "        print(f\"Fold: {fold_number}\")\n",
    "\n",
    "        # load data\n",
    "        X_train, y_train, X_test, y_test = read_fold_data(directory=data_folder_temp, fold_number=fold_number) \n",
    "\n",
    "        print(\"Preview train: \")\n",
    "        print(X_train.shape)\n",
    "        print(\"Preview test: \")\n",
    "        print(X_test.shape)\n",
    "        print(\"preview y train: \")\n",
    "        print(y_train.head(3))\n",
    "        \n",
    "        # train model \n",
    "        model, parameters_temp = train_model(X_train=X_train, y_train=y_train[target], model_name=model_name\n",
    "                      , cv=LeaveOneGroupOut(), cv_groups=X_train.index.get_level_values(crossval_column).values, scoring=\"neg_mean_absolute_error\")\n",
    "        # predict\n",
    "        predictions_train = y_train.rename(columns={target: \"true\"}).copy()\n",
    "        predictions_train['predicted'] = model.predict(X_train)\n",
    "\n",
    "        predictions_test = y_test.rename(columns={target: \"true\"}).copy()\n",
    "        predictions_test['predicted'] = model.predict(X_test)\n",
    "\n",
    "        print(\"Preview predictions test: \")\n",
    "        print(predictions_test.head())\n",
    "        print(predictions_test.shape)   \n",
    "        \n",
    "        # calculate model performance\n",
    "        performance_temp = model_performance_summary(true_train=predictions_train[\"true\"].values\n",
    "                                                , predicted_train=predictions_train[\"predicted\"].values\n",
    "                                                , true_test=predictions_test[\"true\"].values\n",
    "                                                , predicted_test=predictions_test[\"predicted\"].values)\n",
    "        # save \n",
    "        joblib.dump(model, f\"{results_folder_temp}/models/model_fold={str(fold_number)}.joblib\")\n",
    "\n",
    "        parameters_temp[\"fold_number\"] = fold_number\n",
    "        parameters = pd.concat([parameters, parameters_temp], axis=0)\n",
    "\n",
    "        performance_temp[\"fold_number\"] = fold_number\n",
    "        performance = pd.concat([performance, performance_temp], axis=0)\n",
    "\n",
    "        predictions_train.reset_index().to_csv(f\"{results_folder_temp}/predictions/predictions_set=train_fold={fold_number}.csv\", index=False)\n",
    "        predictions_test.reset_index().to_csv(f\"{results_folder_temp}/predictions/predictions_set=test_fold={fold_number}.csv\", index=False)\n",
    "\n",
    "        predictions = pd.concat([predictions, predictions_test], axis=0)\n",
    "        \n",
    "    print(\"Preview parameters: \")\n",
    "    print(parameters.head())\n",
    "    print(parameters.shape)\n",
    "\n",
    "    print(\"Preview perfromance\")\n",
    "    print(performance.head())\n",
    "    print(performance.shape)\n",
    "    \n",
    "    print(\"Preview predictions\")\n",
    "    print(predictions.head())\n",
    "    print(predictions.shape)\n",
    "\n",
    "    # save \n",
    "    performance.to_csv(f\"{results_folder_temp}/models/performance.csv\", index=False)\n",
    "    parameters.to_csv(f\"{results_folder_temp}/models/parameters.csv\", index=False)\n",
    "    predictions.reset_index().to_csv(f\"{results_folder_temp}/predictions/predictions_set=test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
